{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f169cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv(\"megaGymDataset.csv\")\n",
    "df = df.rename(columns={'Unnamed: 0': 'index'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd33a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cheking if there is any NULL or missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403c7d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA ANALYSIS\n",
    "\n",
    "# Some exercises has the same title - Should remove duplicates?\n",
    "df = df.drop_duplicates('Title', keep='last')\n",
    "df['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted bv level\n",
    "df['Level'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3dc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted by type\n",
    "df['Type'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e0bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted by bodypart\n",
    "df['BodyPart'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf387ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top rated exercises\n",
    "ratingSorted= df.sort_values(by='Rating',ascending=False)\n",
    "ratingSorted =ratingSorted.head(10)\n",
    "ratingSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d443051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the row of the given Title to find the index\n",
    "print(df[df[\"Title\"] == \"Bench press\"])\n",
    "df.loc[df['Title'] == \"Bench press\", 'Rating'] = 10\n",
    "print(df[df[\"Title\"] == \"Bench press\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce6d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by=\"Rating\")\n",
    "# Create a histogram of the \"Ratings\" column\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# Create a histogram of the \"Ratings\" column\n",
    "plt.hist(df_sorted[\"Rating\"], bins=20, edgecolor=\"k\", alpha=0.7)\n",
    "\n",
    "plt.title(\"Distribution of Ratings\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(False)\n",
    "plt.xlim(df_sorted[\"Rating\"].min(), df_sorted[\"Rating\"].max())\n",
    "plt.ylim(0, plt.gca().get_ylim()[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753ff69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "# Datasett for trening. Gjør om strenger til kategorier (int)\n",
    "x = deepcopy(df)\n",
    "x = x.drop([\"Title\"], axis = 1)\n",
    "x = x.drop([\"Desc\"], axis = 1)\n",
    "x = x.drop([\"RatingDesc\"], axis = 1)\n",
    "x['Level'] = pd.factorize(x['Level'])[0]\n",
    "x['Type'] = pd.factorize(x['Type'])[0]\n",
    "x['BodyPart'] = pd.factorize(x['BodyPart'])[0]\n",
    "x['Equipment'] = pd.factorize(x['Equipment'])[0]\n",
    "x = x[x['Rating'].notna()]\n",
    "x = x[df[\"Rating\"] != 0]\n",
    "# Verdier som skal predikeres, brukes for trening og testing\n",
    "y = x[\"Rating\"]\n",
    "x = x.drop([\"Rating\"], axis = 1)\n",
    "\n",
    "# Grid search for å finne beste params\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3,5,7,9,11,13,15,17],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=KNeighborsRegressor(), param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "grid_search.fit(x, y)\n",
    "params = grid_search.best_params_\n",
    "\n",
    "# Traiing\n",
    "knn = KNeighborsRegressor(n_neighbors = params['n_neighbors'], p = params[\"p\"])\n",
    "knn.fit(x, y)\n",
    "\n",
    "\n",
    "# Ny variabel X. Alle rader fra dataframe som ikke har rating\n",
    "x = deepcopy(df)\n",
    "# Ekskluderer øvelser med ratings\n",
    "x = df[df['Rating'].isin([0, np.nan])]\n",
    "\n",
    "# Gjør om strenger til kategorier (int) for prediction\n",
    "x = x.drop([\"Rating\"], axis = 1)\n",
    "x = x.drop([\"Title\"], axis = 1)\n",
    "x = x.drop([\"Desc\"], axis = 1)\n",
    "x = x.drop([\"RatingDesc\"], axis = 1)\n",
    "x['Level'] = pd.factorize(x['Level'])[0]\n",
    "x['Type'] = pd.factorize(x['Type'])[0]\n",
    "x['BodyPart'] = pd.factorize(x['BodyPart'])[0]\n",
    "x['Equipment'] = pd.factorize(x['Equipment'])[0]\n",
    "\n",
    "# Antall nonvalues\n",
    "print(\"Nonvalues rating before:\",df[\"Rating\"].isna().sum())\n",
    "\n",
    "# Predikerer en rating for hver rad i dataframe som ikke har rating\n",
    "for index, row in x.iterrows():\n",
    "    rating = knn.predict([row]).round(decimals=1)\n",
    "    df.loc[df['index'] == index, 'Rating'] = rating\n",
    "\n",
    "print(\"Nonvalues rating after\",df[\"Rating\"].isna().sum())\n",
    "\n",
    "filtered_df = df[df[\"Rating\"] == 0]\n",
    "print(len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d3a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by=\"Rating\")\n",
    "# Create a histogram of the \"Ratings\" column\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# Create a histogram of the \"Ratings\" column\n",
    "plt.hist(df_sorted[\"Rating\"], bins=20, edgecolor=\"k\", alpha=0.7)\n",
    "\n",
    "plt.title(\"Distribution of Ratings\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(False)\n",
    "plt.xlim(df_sorted[\"Rating\"].min(), df_sorted[\"Rating\"].max())\n",
    "plt.ylim(0, plt.gca().get_ylim()[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ae6ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing irrelevant columns\n",
    "df = df.drop('RatingDesc', axis=1)\n",
    "# Removing all rows containing nonvalues in description\n",
    "df = df[df['Desc'].notna()]\n",
    "# Removing ID column\n",
    "df.pop(df.columns[0])\n",
    "\n",
    "# Dataset after preprocessing\n",
    "clean_df = deepcopy(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d5987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2546d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging columns for cosign similarity and dropping excess columns\n",
    "df[\"Merged\"] = df[\"Type\"].astype(str) + '|' + \\\n",
    "  df[\"BodyPart\"].astype(str) + '|' + df[\"Equipment\"].astype(str) + '|' + \\\n",
    "  df[\"Level\"]\n",
    "\n",
    "df = df.drop('Type', axis=1)\n",
    "df = df.drop('BodyPart', axis=1)\n",
    "df = df.drop('Equipment', axis=1)\n",
    "df = df.drop('Level', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6dd1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The merged columns\n",
    "df[\"Merged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb7e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting values of the merged column into vectors\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(df.loc[:,\"Merged\"])\n",
    "\n",
    "liste = count_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da5135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim_matrix = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index to avoid indexing errors and NAN values in recommender\n",
    "# This makes the previous indexes invalid\n",
    "# \"drop\" avoids adding the old index as a column\n",
    "df = df.reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe3aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender(data_frame, exercise_id, sim_matrix):\n",
    "    sim_df = pd.DataFrame(sim_matrix[exercise_id],\n",
    "                         columns=[\"Similarity\"])\n",
    "    exercise_titles = data_frame.loc[:, \"Title\"]\n",
    "    exercise_rec = pd.concat([sim_df, exercise_titles], axis = 1)\n",
    "    return exercise_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d7fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the row of the given Title to find the index\n",
    "row = df[df[\"Title\"] == \"Bench press\"]\n",
    "index = row.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c691750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercises similar to bench press\n",
    "df_by_cat = recommender(df, 1115, sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab5e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f164120",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "overview_matrix = tfidf.fit_transform(df[\"Desc\"])\n",
    "overview_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad874e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = linear_kernel(overview_matrix, overview_matrix)\n",
    "print(similarity_matrix[0:5,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfff244",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.Series(df.index, index = df[\"Desc\"])\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9452c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recommender_by_desc(exercise_input, df, similarity_matrix, mapping):\n",
    "    exercise_index = mapping[exercise_input]\n",
    "    if not isinstance(exercise_index, np.int64):\n",
    "        exercise_index = exercise_index[0]\n",
    "    similarity_score = list(enumerate(similarity_matrix[exercise_index]))\n",
    "    score = [tup[1] for tup in similarity_score]\n",
    "    exercise_indices = [i[0] for i in similarity_score]\n",
    "    df2 = df[\"Title\"].iloc[exercise_indices].to_frame()\n",
    "    df2[\"Similarity\"] = score\n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e9db8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_desc = recommender_by_desc(df[\"Desc\"][1115], df, similarity_matrix, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee17945",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_by_cat.copy()\n",
    "merged_df[\"Similarity\"] = (df_by_cat[\"Similarity\"] + df_by_desc[\"Similarity\"]) / 2\n",
    "merged_df = merged_df.sort_values(by=[\"Similarity\"], ascending=False)\n",
    "merged_df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a2dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = deepcopy(clean_df)\n",
    "\n",
    "def knowledge_based_rec(dataframe, type=None, bodypart=None, equipment=None, level=None):\n",
    "    if type:\n",
    "        dataframe = dataframe[df[\"Type\"] == type]\n",
    "    if bodypart:\n",
    "        dataframe = dataframe[df[\"BodyPart\"] == bodypart]\n",
    "    if equipment:\n",
    "        dataframe = dataframe[df[\"Equipment\"] == equipment]\n",
    "    if level:\n",
    "        dataframe = dataframe[df[\"Level\"] == level]\n",
    "\n",
    "    recommendations = dataframe[[\"Title\" , \"Rating\"]]\n",
    "    return recommendations.sort_values(by=\"Rating\", ascending=False).iloc[:10]\n",
    "\n",
    "print(knowledge_based_rec(df, type=\"\", bodypart=\"Chest\", equipment=\"Bands\", level=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6599cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "# Load your gym exercise data into a Pandas DataFrame\n",
    "# Make sure to specify the correct encoding if you have special characters\n",
    "df = deepcopy(clean_df)\n",
    "\n",
    "# Create a tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Gym Exercise Recommender\")\n",
    "\n",
    "# Function to filter and display exercises\n",
    "def recommend_exercises():\n",
    "    selected_bodypart = bodypart_var.get()\n",
    "    selected_level = level_var.get()\n",
    "    selected_type = type_var.get()\n",
    "\n",
    "    filtered_df = df[\n",
    "        (df['BodyPart'] == selected_bodypart) &\n",
    "        (df['Level'] == selected_level) &\n",
    "        (df['Type'] == selected_type)\n",
    "    ]\n",
    "\n",
    "    exercise_list.delete(0, tk.END)  # Clear the listbox\n",
    "\n",
    "    for i, title in enumerate(filtered_df['Title']):\n",
    "        exercise_list.insert(tk.END, f'{i + 1}. {title}')\n",
    "\n",
    "# Create and configure GUI elements\n",
    "bodypart_label = ttk.Label(root, text=\"Select Body Part:\")\n",
    "bodypart_label.pack()\n",
    "my_bps = [i for i in df[\"BodyPart\"].unique()]\n",
    "bodypart_var = ttk.Combobox(root, values=my_bps)\n",
    "bodypart_var.pack()\n",
    "\n",
    "level_label = ttk.Label(root, text=\"Select Level:\")\n",
    "level_label.pack()\n",
    "my_levels = [i for i in df[\"Level\"].unique()]\n",
    "level_var = ttk.Combobox(root, values=my_levels)\n",
    "level_var.pack()\n",
    "\n",
    "type_label = ttk.Label(root, text=\"Select Type:\")\n",
    "type_label.pack()\n",
    "my_types = [i for i in df[\"Type\"].unique()]\n",
    "type_var = ttk.Combobox(root, values=my_types)\n",
    "type_var.pack()\n",
    "\n",
    "recommend_button = ttk.Button(root, text=\"Recommend Exercises\", command=recommend_exercises)\n",
    "recommend_button.pack()\n",
    "\n",
    "exercise_list = tk.Listbox(root)\n",
    "#exercise_list.pack()\n",
    "\n",
    "#root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9853ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collaborative filtering\n",
    "\"\"\"\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "ratings_df = pd.read_csv(\"user_ratings.csv\")\n",
    "ratings = ratings_df.melt(id_vars=['Users'], var_name='Exercise', value_name='Rating')\n",
    "ratings.to_csv(\"ratings2.csv\")\n",
    "\n",
    "ratings = pd.read_csv(\"ratings2.csv\")\n",
    "ratings = ratings.drop(\"Unnamed: 0\", axis=1)\n",
    "ratings['Exercise'] = pd.factorize(ratings['Exercise'])[0]\n",
    "\n",
    "# Use ratings DataFrame for pivoting\n",
    "ratings_full = ratings.pivot(index=\"Users\", columns=\"Exercise\", values=\"Rating\")\n",
    "\n",
    "# Now you can use ratings_full for further analysis\n",
    "ratings_full\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collaborative filtering\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "# Leser DataFrame\n",
    "ratings_df = pd.read_csv(\"user_ratings.csv\")\n",
    "\n",
    "# Converting to the correct format\n",
    "ratings = ratings_df.melt(id_vars=['Users'], var_name='Exercise', value_name='Rating')\n",
    "#ratings\n",
    "\n",
    "# Factorization?\n",
    "#ratings['Exercise'] = pd.factorize(ratings['Exercise'])[0]\n",
    "\n",
    "# Use ratings DataFrame for pivoting\n",
    "ratings_full = ratings.pivot(index=\"Users\", columns=\"Exercise\", values=\"Rating\")\n",
    "ratings_full.fillna(0).astype(int)\n",
    "\n",
    "# Training\n",
    "reader = Reader(rating_scale=(1,10))\n",
    "data = Dataset.load_from_df(ratings[[\"Users\", \"Exercise\", \"Rating\"]], reader)\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Variables\n",
    "user_rating = trainset.ur\n",
    "item_rating = trainset.ir\n",
    "num_users = trainset.n_users\n",
    "num_items = trainset.n_items\n",
    "num_ratings = trainset.n_ratings\n",
    "\n",
    "print(\"Users\", num_users)\n",
    "print(\"Items\", num_items)\n",
    "print(\"Ratings\", num_ratings)\n",
    "density = num_ratings / (num_users * num_items) \n",
    "density = np.round(density, decimals=2)\n",
    "sparsity = 1 - density\n",
    "print(\"Density:\", density*100, \"%\")\n",
    "print(\"Sparsity:\", sparsity*100, \"%\")\n",
    "\n",
    "\n",
    "sim_options = {\"name\": \"pearson\",\n",
    "               \"user based\": True,\n",
    "               \"shrinkage\": 0}\n",
    "\n",
    "rec = KNNBasic(sim_options=sim_options)\n",
    "rec.fit(trainset)\n",
    "\n",
    "user_sim_matrix = rec.sim\n",
    "user_sim_matrix\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
