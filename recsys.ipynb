{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "bigdf = pd.read_csv(\"megaGymDataset.csv\")\n",
    "bigdf = bigdf.rename(columns={'Unnamed: 0': 'index'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef005e46",
   "metadata": {},
   "source": [
    "<h1>Data analisys</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c71004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some exercises has the same title - Should remove duplicates?\n",
    "bigdf = bigdf.drop_duplicates('Title', keep='last')\n",
    "bigdf['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51413288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted bv level\n",
    "bigdf['Level'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77203ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted by type\n",
    "bigdf['Type'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89321233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted by bodypart\n",
    "bigdf['BodyPart'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93473d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top rated exercises\n",
    "ratingSorted= bigdf.sort_values(by='Rating',ascending=False)\n",
    "ratingSorted =ratingSorted.head(10)\n",
    "ratingSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5bf180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of ratings\n",
    "\n",
    "df_sorted = bigdf.sort_values(by=\"Rating\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_sorted[\"Rating\"], bins=20, edgecolor=\"k\", alpha=0.7)\n",
    "\n",
    "plt.title(\"Distribution of Ratings\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(False)\n",
    "plt.xlim(df_sorted[\"Rating\"].min(), df_sorted[\"Rating\"].max())\n",
    "plt.ylim(0, plt.gca().get_ylim()[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f2591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "# Dataset for training. Converts all strings to categories (int) for KNN algorithm\n",
    "x = deepcopy(bigdf)\n",
    "x = x.drop([\"Title\"], axis = 1)\n",
    "x = x.drop([\"Desc\"], axis = 1)\n",
    "x = x.drop([\"RatingDesc\"], axis = 1)\n",
    "x['Level'] = pd.factorize(x['Level'])[0]\n",
    "x['Type'] = pd.factorize(x['Type'])[0]\n",
    "x['BodyPart'] = pd.factorize(x['BodyPart'])[0]\n",
    "x['Equipment'] = pd.factorize(x['Equipment'])[0]\n",
    "x = x[x['Rating'].notna()]\n",
    "x = x[x[\"Rating\"] != 0]\n",
    "\n",
    "# Values to be predicted\n",
    "y = x[\"Rating\"]\n",
    "x = x.drop([\"Rating\"], axis = 1)\n",
    "\n",
    "# Grid search to find the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3,5,7,9,11,13,15,17],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=KNeighborsRegressor(), param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "grid_search.fit(x, y)\n",
    "params = grid_search.best_params_\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=3)\n",
    "\n",
    "\n",
    "# Training\n",
    "knn = KNeighborsRegressor(n_neighbors = params['n_neighbors'], p = params[\"p\"])\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "pred = knn.predict(x_test)\n",
    "\n",
    "print(\"Evaluating the prediction\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, pred):.2f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, pred):.2f}\")\n",
    "print(f\"R-squared (R^2): {r2_score(y_test, pred):.2f}\")\n",
    "\n",
    "\n",
    "# New X, all exercises without ratings\n",
    "x = deepcopy(bigdf)\n",
    "\n",
    "# Excluding exercises with ratings\n",
    "x = x[x['Rating'].isin([0, np.nan])]\n",
    "x = x.drop([\"Rating\"], axis = 1)\n",
    "x = x.drop([\"Title\"], axis = 1)\n",
    "x = x.drop([\"Desc\"], axis = 1)\n",
    "x = x.drop([\"RatingDesc\"], axis = 1)\n",
    "x['Level'] = pd.factorize(x['Level'])[0]\n",
    "x['Type'] = pd.factorize(x['Type'])[0]\n",
    "x['BodyPart'] = pd.factorize(x['BodyPart'])[0]\n",
    "x['Equipment'] = pd.factorize(x['Equipment'])[0]\n",
    "\n",
    "# Amount of nonvalues\n",
    "print(\"Nonvalues before:\",bigdf[\"Rating\"].isna().sum())\n",
    "\n",
    "# All exercises without ratings are given a predicted rating\n",
    "for index, row in x.iterrows():\n",
    "    rating = knn.predict([row]).round(decimals=1)\n",
    "    bigdf.loc[bigdf['index'] == index, 'Rating'] = rating\n",
    "\n",
    "# Nonvalues after prediction\n",
    "print(\"Nonvalues after\",bigdf[\"Rating\"].isna().sum())\n",
    "\n",
    "filtered_df = bigdf[bigdf[\"Rating\"] == 0]\n",
    "print(len(filtered_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04353da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings after KNN predicion\n",
    "\n",
    "df_sorted = bigdf.sort_values(by=\"Rating\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_sorted[\"Rating\"], bins=20, edgecolor=\"k\", alpha=0.7)\n",
    "\n",
    "plt.title(\"Distribution of Ratings\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(False)\n",
    "plt.xlim(df_sorted[\"Rating\"].min(), df_sorted[\"Rating\"].max())\n",
    "plt.ylim(0, plt.gca().get_ylim()[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c904f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing irrelevant columns\n",
    "bigdf = bigdf.drop('RatingDesc', axis=1)\n",
    "# Removing all rows containing nonvalues in description\n",
    "bigdf = bigdf[bigdf['Desc'].notna()]\n",
    "# Removing ID column\n",
    "bigdf.pop(bigdf.columns[0])\n",
    "\n",
    "# Dataset after preprocessing\n",
    "clean_df = deepcopy(bigdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5166c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb7fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller dataframe consisting of 120 exercises\n",
    "\n",
    "smalldf = pd.read_csv(\"100_exercises.csv\", sep=\";\", names = [\"index\", \"Title\"])\n",
    "bigdf['Title'] = bigdf['Title'].str.lower()\n",
    "smalldf['Title'] = smalldf['Title'].str.lower()\n",
    "combined = pd.merge(bigdf, smalldf, on=\"Title\", how='inner')\n",
    "\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffaaf1",
   "metadata": {},
   "source": [
    "<h1>Cosine similarity</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd4a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the row of the given Title to find the index\n",
    "print(bigdf[bigdf[\"Title\"] == \"bench press\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c9798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging columns for cosign similarity and dropping excess columns\n",
    "bigdf[\"Merged\"] = bigdf[\"Type\"].astype(str) + '|' + \\\n",
    "  bigdf[\"BodyPart\"].astype(str) + '|' + bigdf[\"Equipment\"].astype(str) + '|' + \\\n",
    "  bigdf[\"Level\"]\n",
    "\n",
    "bigdf = bigdf.drop('Type', axis=1)\n",
    "bigdf = bigdf.drop('BodyPart', axis=1)\n",
    "bigdf = bigdf.drop('Equipment', axis=1)\n",
    "bigdf = bigdf.drop('Level', axis=1)\n",
    "\n",
    "# The merged columns\n",
    "bigdf[\"Merged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3834b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting values of the merged column into vectors\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(bigdf.loc[:,\"Merged\"])\n",
    "\n",
    "liste = count_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbed6e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim_matrix = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b9ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ee5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index to avoid indexing errors and NAN values in recommender\n",
    "# This makes the previous indexes invalid\n",
    "# \"drop\" avoids adding the old index as a column\n",
    "bigdf = bigdf.reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d931e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender(data_frame, exercise_id, sim_matrix):\n",
    "    sim_df = pd.DataFrame(sim_matrix[exercise_id],\n",
    "                         columns=[\"Similarity\"])\n",
    "    exercise_titles = data_frame.loc[:, \"Title\"]\n",
    "    exercise_rec = pd.concat([sim_df, exercise_titles], axis = 1)\n",
    "    exercise_rec = exercise_rec.sort_values(by=\"Similarity\", ascending=False)\n",
    "    \n",
    "    return exercise_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb22e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the row of the given Title to find the index\n",
    "print(bigdf[bigdf[\"Title\"] == \"bench press\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e9d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercises similar to bench press\n",
    "df_by_cat = recommender(bigdf, 450, sim_matrix)\n",
    "df_by_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2e5faa",
   "metadata": {},
   "source": [
    "<h1>TDIDF</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d4ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "overview_matrix = tfidf.fit_transform(bigdf[\"Desc\"])\n",
    "overview_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = linear_kernel(overview_matrix, overview_matrix)\n",
    "print(similarity_matrix[0:5,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e3b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.Series(bigdf.index, index = bigdf[\"Desc\"])\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b63063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender_by_desc(exercise_input, df, similarity_matrix, mapping):\n",
    "    exercise_index = mapping[exercise_input]\n",
    "    if not isinstance(exercise_index, np.int64):\n",
    "        exercise_index = exercise_index[0]\n",
    "    similarity_score = list(enumerate(similarity_matrix[exercise_index]))\n",
    "    score = [tup[1] for tup in similarity_score]\n",
    "    exercise_indices = [i[0] for i in similarity_score]\n",
    "    df2 = df[\"Title\"].iloc[exercise_indices].to_frame()\n",
    "    df2[\"Similarity\"] = score\n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ff424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_desc = recommender_by_desc(bigdf[\"Desc\"][450], bigdf, similarity_matrix, mapping)\n",
    "df_by_desc.sort_values(by=\"Similarity\", ascending=False).iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf3a55",
   "metadata": {},
   "source": [
    "<h1>Combined recommender (Cosine similarity + TDIDF)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_by_cat.copy()\n",
    "merged_df[\"Similarity\"] = (df_by_cat[\"Similarity\"] + df_by_desc[\"Similarity\"]) / 2\n",
    "merged_df = merged_df.sort_values(by=[\"Similarity\"], ascending=False)\n",
    "merged_df[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ad153b",
   "metadata": {},
   "source": [
    "<h1>Constraint based recommender</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1212162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe without merged columns\n",
    "df = deepcopy(clean_df)\n",
    "\n",
    "def knowledge_based_rec(dataframe, type=None, bodypart=None, equipment=None, level=None):\n",
    "    #return dataframe\n",
    "\n",
    "    if type:\n",
    "        dataframe = dataframe[dataframe[\"Type\"] == type]\n",
    "    if bodypart:\n",
    "        dataframe = dataframe[dataframe[\"BodyPart\"] == bodypart]\n",
    "    if equipment:\n",
    "        dataframe = dataframe[dataframe[\"Equipment\"] == equipment]\n",
    "    if level:\n",
    "        dataframe = dataframe[dataframe[\"Level\"] == level]\n",
    "\n",
    "    recommendations = dataframe[[\"Title\" , \"Rating\"]]\n",
    "    return recommendations.sort_values(by=\"Rating\", ascending=False).iloc[:10]\n",
    "\n",
    "print(knowledge_based_rec(df, type=\"\", bodypart=\"Chest\", equipment=\"Barbell\", level=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f80098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMALL DATAFRAME\n",
    "df = deepcopy(combined)\n",
    "def knowledge_based_rec(dataframe, type=None, bodypart=None, equipment=None, level=None):\n",
    "    if type:\n",
    "        dataframe = dataframe[df[\"Type\"] == type]\n",
    "    if bodypart:\n",
    "        dataframe = dataframe[df[\"BodyPart\"] == bodypart]\n",
    "    if equipment:\n",
    "        dataframe = dataframe[df[\"Equipment\"] == equipment]\n",
    "    if level:\n",
    "        dataframe = dataframe[df[\"Level\"] == level]\n",
    "\n",
    "    recommendations = dataframe[[\"Title\" , \"Rating\"]]\n",
    "    return recommendations.sort_values(by=\"Rating\", ascending=False).iloc[:10]\n",
    "\n",
    "print(knowledge_based_rec(df, type=\"\", bodypart=\"Chest\", equipment=\"Barbell\", level=\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c844d388",
   "metadata": {},
   "source": [
    "<h1>Knowledge based GUI</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b44d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a9f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "# Load your gym exercise data into a Pandas DataFrame\n",
    "# Make sure to specify the correct encoding if you have special characters\n",
    "df = deepcopy(combined)\n",
    "\n",
    "# Create a tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Gym Exercise Recommender\")\n",
    "\n",
    "# Function to filter and display exercises\n",
    "def recommend_exercises():\n",
    "    selected_bodypart = bodypart_var.get()\n",
    "    selected_level = level_var.get()\n",
    "    selected_type = type_var.get()\n",
    "\n",
    "    filtered_df = df[\n",
    "        (df['BodyPart'] == selected_bodypart) &\n",
    "        (df['Level'] == selected_level) &\n",
    "        (df['Type'] == selected_type)\n",
    "    ]\n",
    "\n",
    "    exercise_list.delete(0, tk.END)  # Clear the listbox\n",
    "\n",
    "    for i, title in enumerate(filtered_df['Title']):\n",
    "        exercise_list.insert(tk.END, f'{i + 1}. {title}')\n",
    "\n",
    "# Create and configure GUI elements\n",
    "bodypart_label = ttk.Label(root, text=\"Select Body Part:\")\n",
    "bodypart_label.pack()\n",
    "my_bps = [i for i in df[\"BodyPart\"].unique()]\n",
    "bodypart_var = ttk.Combobox(root, values=my_bps)\n",
    "bodypart_var.pack()\n",
    "\n",
    "level_label = ttk.Label(root, text=\"Select Level:\")\n",
    "level_label.pack()\n",
    "my_levels = [i for i in df[\"Level\"].unique()]\n",
    "level_var = ttk.Combobox(root, values=my_levels)\n",
    "level_var.pack()\n",
    "\n",
    "type_label = ttk.Label(root, text=\"Select Type:\")\n",
    "type_label.pack()\n",
    "my_types = [i for i in df[\"Type\"].unique()]\n",
    "type_var = ttk.Combobox(root, values=my_types)\n",
    "type_var.pack()\n",
    "\n",
    "recommend_button = ttk.Button(root, text=\"Recommend Exercises\", command=recommend_exercises)\n",
    "recommend_button.pack()\n",
    "\n",
    "exercise_list = tk.Listbox(root)\n",
    "exercise_list.pack()\n",
    "\n",
    "#root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6599cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "# Load your gym exercise data into a Pandas DataFrame\n",
    "# Make sure to specify the correct encoding if you have special characters\n",
    "df = deepcopy(clean_df)\n",
    "\n",
    "# Create a tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Gym Exercise Recommender\")\n",
    "\n",
    "# Function to filter and display exercises\n",
    "def recommend_exercises():\n",
    "    selected_bodypart = bodypart_var.get()\n",
    "    selected_level = level_var.get()\n",
    "    selected_type = type_var.get()\n",
    "\n",
    "    filtered_df = df[\n",
    "        (df['BodyPart'] == selected_bodypart) &\n",
    "        (df['Level'] == selected_level) &\n",
    "        (df['Type'] == selected_type)\n",
    "    ]\n",
    "\n",
    "    exercise_list.delete(0, tk.END)  # Clear the listbox\n",
    "\n",
    "    for i, title in enumerate(filtered_df['Title']):\n",
    "        exercise_list.insert(tk.END, f'{i + 1}. {title}')\n",
    "\n",
    "# Create and configure GUI elements\n",
    "bodypart_label = ttk.Label(root, text=\"Select Body Part:\")\n",
    "bodypart_label.pack()\n",
    "my_bps = [i for i in df[\"BodyPart\"].unique()]\n",
    "bodypart_var = ttk.Combobox(root, values=my_bps)\n",
    "bodypart_var.pack()\n",
    "\n",
    "level_label = ttk.Label(root, text=\"Select Level:\")\n",
    "level_label.pack()\n",
    "my_levels = [i for i in df[\"Level\"].unique()]\n",
    "level_var = ttk.Combobox(root, values=my_levels)\n",
    "level_var.pack()\n",
    "\n",
    "type_label = ttk.Label(root, text=\"Select Type:\")\n",
    "type_label.pack()\n",
    "my_types = [i for i in df[\"Type\"].unique()]\n",
    "type_var = ttk.Combobox(root, values=my_types)\n",
    "type_var.pack()\n",
    "\n",
    "recommend_button = ttk.Button(root, text=\"Recommend Exercises\", command=recommend_exercises)\n",
    "recommend_button.pack()\n",
    "\n",
    "exercise_list = tk.Listbox(root)\n",
    "#exercise_list.pack()\n",
    "\n",
    "#root.mainloop() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b4ffd5",
   "metadata": {},
   "source": [
    "<h1>Collaborative</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9853ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collaborative filtering\n",
    "\"\"\"\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "ratings_df = pd.read_csv(\"user_ratings.csv\")\n",
    "ratings = ratings_df.melt(id_vars=['Users'], var_name='Exercise', value_name='Rating')\n",
    "ratings.to_csv(\"ratings2.csv\")\n",
    "\n",
    "ratings = pd.read_csv(\"ratings2.csv\")\n",
    "ratings = ratings.drop(\"Unnamed: 0\", axis=1)\n",
    "ratings['Exercise'] = pd.factorize(ratings['Exercise'])[0]\n",
    "\n",
    "# Use ratings DataFrame for pivoting\n",
    "ratings_full = ratings.pivot(index=\"Users\", columns=\"Exercise\", values=\"Rating\")\n",
    "\n",
    "# Now you can use ratings_full for further analysis\n",
    "ratings_full\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2d208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collaborative filtering\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Leser DataFrame\n",
    "ratings_df = pd.read_csv(\"user_ratings.csv\")\n",
    "\n",
    "# Converting to the correct format\n",
    "ratings = ratings_df.melt(id_vars=['Users'], var_name='Exercise', value_name='Rating')\n",
    "\n",
    "# Factorization?\n",
    "ratings['Exercise'] = pd.factorize(ratings['Exercise'])[0]\n",
    "# Use ratings DataFrame for pivoting\n",
    "ratings = ratings.fillna(0).astype(int)\n",
    "# Training\n",
    "\n",
    "reader = Reader(rating_scale=(1,10))\n",
    "data = Dataset.load_from_df(ratings[[\"Users\", \"Exercise\", \"Rating\"]], reader)\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Variables\n",
    "user_rating = trainset.ur\n",
    "item_rating = trainset.ir\n",
    "num_users = trainset.n_users\n",
    "num_items = trainset.n_items\n",
    "num_ratings = trainset.n_ratings\n",
    "\n",
    "print(\"Users\", num_users)\n",
    "print(\"Items\", num_items)\n",
    "print(\"Ratings\", num_ratings)\n",
    "density = num_ratings / (num_users * num_items) \n",
    "density = np.round(density, decimals=2)\n",
    "sparsity = 1 - density\n",
    "print(\"Density:\", density*100, \"%\")\n",
    "print(\"Sparsity:\", sparsity*100, \"%\")\n",
    "\n",
    "\n",
    "sim_options = {\"name\": \"pearson\",\n",
    "               \"user based\": True,\n",
    "               \"shrinkage\": 0}\n",
    "\n",
    "rec = KNNBasic(sim_options=sim_options)\n",
    "rec.fit(trainset)\n",
    "\n",
    "user_sim_matrix = rec.sim\n",
    "#user_sim_matrix\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96cdf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def userbased_cf(user):\n",
    "    # CF fra Youtube\n",
    "    # Leser DataFrame\n",
    "    ratings2 = pd.read_csv(\"user_ratings.csv\")\n",
    "\n",
    "    #ratings = ratings.melt(id_vars=['Users'], var_name='Exercise', value_name='Rating')\n",
    "\n",
    "\n",
    "    ratings2 = ratings2.drop(columns=\"Users\")\n",
    "    ratings2.index.name = \"Users\"\n",
    "    ratings2.columns.name = \"Exercises\"\n",
    "    ratings_norm = ratings2.copy()\n",
    "    ratings_norm = ratings_norm.subtract(ratings2.mean(axis=1), axis = \"rows\")\n",
    "    \n",
    "    user_similarity = ratings_norm.T.corr()\n",
    "    picked_user = user\n",
    "\n",
    "    user_similarity.drop(index=picked_user, inplace=True)\n",
    "    \n",
    "    n = 10\n",
    "\n",
    "    user_similarity_threshold = 0.3\n",
    "\n",
    "    similar_users = user_similarity[user_similarity[picked_user]>user_similarity_threshold][picked_user].sort_values(ascending=False)[:n]\n",
    "    picked_user_done = ratings_norm[ratings_norm.index == picked_user].dropna(axis=1, how=\"all\")\n",
    "    similar_user_exercises = ratings_norm[ratings_norm.index.isin(similar_users.index)].dropna(axis=1, how=\"all\")\n",
    "    similar_user_exercises.drop(picked_user_done.columns, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "    # A dictionary to store item scores\n",
    "    item_score = {}\n",
    "\n",
    "    # Loop through items\n",
    "    for i in similar_user_exercises.columns:\n",
    "        # Get the ratings for movie i\n",
    "        movie_rating = similar_user_exercises[i]\n",
    "        # Create a variable to store the score\n",
    "        total = 0\n",
    "        # Create a variable to store the number of scores\n",
    "        count = 0\n",
    "        # Loop through similar users\n",
    "        for u in similar_users.index:\n",
    "            # If the movie has rating\n",
    "            if pd.isna(movie_rating[u]) == False:\n",
    "                # Score is the sum of user similarity score multiply by the movie rating\n",
    "                score = similar_users[u] * movie_rating[u]\n",
    "                # Add the score to the total score for the movie so far\n",
    "                total += score\n",
    "                # Add 1 to the count\n",
    "                count +=1\n",
    "        # Get the average score for the item\n",
    "        item_score[i] = total / count\n",
    "\n",
    "    # Convert dictionary to pandas dataframe\n",
    "    item_score = pd.DataFrame(item_score.items(), columns=['exercise', 'exercise_score'])\n",
    "    \n",
    "    # Sort the movies by score\n",
    "    ranked_item_score = item_score.sort_values(by=\"exercise_score\", ascending=False)\n",
    "\n",
    "    # Select top m movies\n",
    "    m = 10\n",
    "    \"\"\"\"\n",
    "    # Average rating for the picked user\n",
    "    avg_rating = ratings[ratings.index == picked_user].T.mean(skipna=True)[picked_user]\n",
    "\n",
    "    # Print the average movie rating for user 1\n",
    "    print(f'The average exercise rating for user {picked_user} is {avg_rating:.2f}')\n",
    "\n",
    "    # Calcuate the predicted rating\n",
    "    ranked_item_score['predicted_rating'] = ranked_item_score['exercise_score'] + avg_rating\n",
    "\n",
    "    # Take a look at the data\n",
    "    ranked_item_score.head(m)\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    return(ranked_item_score.head(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb7b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "userbased_cf(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER BASED + EVALUATION\n",
    "\n",
    "\n",
    "#Import the train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Assign X as the original ratings dataframe and y as the user_id column of ratings.\n",
    "X = ratings.copy()\n",
    "y = ratings[\"Users\"]\n",
    "\n",
    "#Split into training and test datasets, stratified along user_id\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify=y, random_state=42)\n",
    "\n",
    "## Stratified random sampling: is a method to ensure that each sample it's likely to occur in after the split.\n",
    "## random_state: \n",
    "r_matrix = X_train.pivot_table(values='Rating', index='Users', columns='Exercise')\n",
    "r_matrix = r_matrix.fillna(0).astype(int)\n",
    "print(r_matrix.head())\n",
    "\n",
    "def cf_user_mean(user, exercise):\n",
    "    \n",
    "    #Check if movie_id exists in r_matrix\n",
    "    if exercise in r_matrix:\n",
    "        #Compute the mean of all the ratings given to the movie\n",
    "        mean_rating = r_matrix[exercise].mean() \n",
    "    else:\n",
    "        #Default to a rating of 3.0 in the absence of any information\n",
    "        mean_rating = 5.0\n",
    "    \n",
    "    return mean_rating\n",
    "\n",
    "#Import the mean_squared_error function\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Function that computes the root mean squared error (or RMSE)\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "#Function to compute the RMSE score obtained on the testing set by a model\n",
    "def score(cf_model):\n",
    "    \n",
    "    #Construct a list of user-movie tuples from the testing dataset\n",
    "    id_pairs = zip(X_test['Users'], X_test['Exercise'])\n",
    "    \n",
    "    #Predict the rating for every user-movie tuple\n",
    "    y_pred = np.array([cf_model(User, Exercise) for (User, Exercise) in id_pairs])\n",
    "    \n",
    "    \n",
    "    #Extract the actual ratings given by the users in the test data\n",
    "    y_true = np.array(X_test['Rating'])\n",
    "    \n",
    "    #Return the final RMSE score\n",
    "    return rmse(y_true, y_pred)\n",
    "\n",
    "#Define the baseline model to always return 3.\n",
    "def baseline(User, Exercise):\n",
    "    return 5.0\n",
    "\n",
    "\n",
    "print(score(baseline))\n",
    "print(score(cf_user_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f70ba3",
   "metadata": {},
   "source": [
    "<h1>Evaluation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f50df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "\n",
    "from eval_metrics import precision_recall_at_k\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import KNNBaseline\n",
    "from surprise import BaselineOnly\n",
    "from surprise import NormalPredictor\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import KFold\n",
    "from tabulate import tabulate\n",
    "\n",
    "ratings_df = pd.read_csv(\"user_ratings.csv\")\n",
    "\n",
    "# Converting to the correct format\n",
    "ratings = ratings_df.melt(id_vars=['Users'], var_name='Exercise', value_name='Rating')\n",
    "\n",
    "# Factorization?\n",
    "ratings['Exercise'] = pd.factorize(ratings['Exercise'])[0]\n",
    "# Use ratings DataFrame for pivoting\n",
    "ratings = ratings.fillna(0).astype(int)\n",
    "# Training\n",
    "\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(ratings.iloc[:,0:3], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.3)\n",
    "\n",
    "table = []\n",
    "rec_n = 0\n",
    "\n",
    "recommenders = (SVD, SVDpp, KNNBasic, KNNBaseline, BaselineOnly, NormalPredictor)\n",
    "titles = (\"SVD\", \"SVD++\", \"KNN-Basic\", \"KNN-Baseline\", \"Baseline\", \"Random\")\n",
    "\n",
    "for rec in recommenders:\n",
    "    rec_alg = rec()\n",
    "    rec_alg.fit(trainset)\n",
    "    predictions = rec_alg.test(testset)\n",
    "\n",
    "    p, r = precision_recall_at_k(predictions, k=4, threshold=4)\n",
    "    precision = \"{:.3f}\".format(p)\n",
    "    recall = \"{:.3f}\".format(r)\n",
    "\n",
    "    new_line = [titles[rec_n], precision, recall]\n",
    "    table.append(new_line)\n",
    "    rec_n += 1\n",
    "\n",
    "header = [\"recommenders\", \"precision\", \"recall\"]\n",
    "print(tabulate(table, header, tablefmt=\"pipe\"))\n",
    "#print(ratings.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ed795",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(\"user_ratings.csv\")\n",
    "\n",
    "# Converting to the correct format\n",
    "ratings = ratings_df.melt(id_vars=['Users'], var_name='Exercise', value_name='Rating')\n",
    "\n",
    "# Factorization?\n",
    "ratings['Exercise'] = pd.factorize(ratings['Exercise'])[0]\n",
    "# Use ratings DataFrame for pivoting\n",
    "ratings = ratings.fillna(0).astype(int)\n",
    "# Training\n",
    "\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(ratings.iloc[:,0:3], reader)\n",
    "\n",
    "kf = KFold(random_state=0)\n",
    "\n",
    "table = []\n",
    "fold_n = 0\n",
    "for rec in recommenders:\n",
    "    out = cross_validate(rec(), data, [\"rmse\", \"mae\", \"fcp\",], kf)\n",
    "    mean_rmse = \"{:.3f}\".format(np.mean(out[\"test_rmse\"]))\n",
    "    mean_mae = \"{:.3f}\".format(np.mean(out[\"test_mae\"]))\n",
    "    mean_fcp = \"{:.3f}\".format(np.mean(out[\"test_fcp\"]))\n",
    "    fit_time = \"{:.3f}\".format(np.mean(out[\"fit_time\"]))\n",
    "\n",
    "    new_line = [titles[fold_n], mean_rmse, mean_mae, mean_fcp, fit_time]\n",
    "    table.append(new_line)\n",
    "    fold_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d9f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"Recommenders\", \"Pred Accuracy [RMSE]\", \"Pred Accuracy [MAE]\", \"Pred Accuracy [FCP]\", \"Training Time [sec]\"]\n",
    "print(tabulate(table, header, tablefmt=\"pipe\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
